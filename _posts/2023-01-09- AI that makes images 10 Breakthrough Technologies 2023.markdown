---
layout: post
title:  AI that makes images 10 Breakthrough Technologies 2023

date:   2023-01-09 06:44:00 +0300
image:  /assets/images/blog/post-20.jpg
author: Will Douglas Heavenarchive page
tags:   MIT Technology Review
---
<br><br><br><br>

WHO
OpenAI, Stability AI, Midjourney, Google

WHEN
Now

OpenAI introduced a world of weird and wonderful mash-ups when its text-to-image model DALL-E was released in 2021. Type in a short description of pretty much anything, and the program spat out a picture of what you asked for in seconds. DALL-E 2, unveiled in April 2022, was a massive leap forward. Google also launched its own image-making AI, called Imagen. 
<br>
OpenAI는 2021년 텍스트 이미지 모델 DALL-E가 출시되었을 때 이상하고 멋진 매시업의 세계를 소개했다. 거의 모든 것에 대한 짧은 설명을 입력하면 프로그램은 당신이 요청한 것의 사진을 몇 초 만에 뱉어낸다. 2022년 4월에 공개된 DALL-E 2는 거대한 도약이었다. 구글은 또한 Imagen이라고 불리는 그들만의 이미지를 만드는 인공지능을 출시했다.

Yet the biggest game-changer was Stable Diffusion, an open-source text-to-image model released for free by UK-based startup Stability AI in August. Not only could Stable Diffusion produce some of the most stunning images yet, but it was designed to run on a (good) home computer.
<br>
그러나 가장 큰 게임 체인저는 영국에 기반을 둔 스타트업 스태빌리티 AI가 8월에 무료로 출시한 오픈 소스 텍스트-이미지 모델인 스테이블 디퓨전이었다. 스테이블 디퓨전은 지금까지 가장 놀라운 이미지를 만들어낼 수 있었을 뿐만 아니라 (좋은) 가정용 컴퓨터에서 실행되도록 설계되었다.

By making text-to-image models accessible to all, Stability AI poured fuel on what was already an inferno of creativity and innovation. Millions of people have created tens of millions of images in just a few months. But there are problems, too. Artists are caught in the middle of one of the biggest upheavals in a decade. And, just like language models, text-to-image generators can amplify the biased and toxic associations buried in training data scraped from the internet.
<br>
Stability AI는 텍스트-이미지 모델을 모두가 접근할 수 있도록 함으로써 이미 창의성과 혁신의 불길에 기름을 부었다. 수백만 명의 사람들이 단 몇 달 만에 수천만 개의 이미지를 만들었습니다. 하지만 문제도 있습니다. 예술가들은 10년 만에 가장 큰 격변 중 하나에 휘말렸다. 그리고 언어 모델과 마찬가지로 텍스트-이미지 생성기는 인터넷에서 긁어낸 훈련 데이터에 묻혀 있는 편향되고 독성 있는 연관성을 증폭시킬 수 있다.

The tech is now being built into commercial software, such as Photoshop. Visual-effects artists and video-game studios are exploring how it can fast-track development pipelines. And text-to-image technology has already advanced to text-to-video. The AI-generated video clips demoed by Google, Meta, and others in the last few months are only seconds long, but that will change. One day movies could be made just by feeding a script into a computer.
<br>
그 기술은 현재 포토샵과 같은 상용 소프트웨어에 내장되어 있다. 시각 효과 아티스트와 비디오 게임 스튜디오는 개발 파이프라인을 빠르게 추적할 수 있는 방법을 모색하고 있습니다. 그리고 텍스트-이미지 기술은 이미 텍스트-비디오 기술로 발전했다. 지난 몇 달 동안 구글, 메타 등이 시연한 AI 생성 동영상은 몇 초 길이에 불과하지만 변화가 있을 것이다. 어느 날 영화는 컴퓨터에 대본을 입력하는 것만으로도 만들어질 수 있었다.

Nothing else in AI grabbed people’s attention more last year—for the best and worst reasons. Now we wait to see what lasting impact these tools will have on creative industries—and the entire field of AI.
<br>
인공지능의 다른 어떤 것도 작년에 사람들의 관심을 더 많이 끌지 못했다. 가장 좋은 이유와 최악의 이유 때문이다. 이제 우리는 이러한 도구들이 창의적인 산업과 AI의 전체 분야에 어떤 지속적인 영향을 미칠지 지켜볼 것이다.

> <a href="https://www.technologyreview.com/2023/01/09/1064864/image-making-ai-10-breakthrough-technologies-2023/">기사</a>

